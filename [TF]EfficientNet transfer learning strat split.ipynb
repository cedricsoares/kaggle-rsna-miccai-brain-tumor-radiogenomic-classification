{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7114.048863,
      "end_time": "2021-10-14T18:43:21.406012",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-10-14T16:44:47.357149",
      "version": "2.3.3"
    },
    "colab": {
      "name": "P8_01_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0iZBs661QCO"
      },
      "source": [
        "# Comptétion Kaggle RSNA-MICCAI Brain Tumor Radiogenomic Classification\n",
        "---\n",
        "\n"
      ],
      "id": "S0iZBs661QCO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MZlbt-92BRc"
      },
      "source": [
        "## Contexte"
      ],
      "id": "1MZlbt-92BRc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhnBp0c12DeR"
      },
      "source": [
        "Ce notebook regroupe les travaux présentés dans le cadre de la compétition [Kaggle RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification). Le concours s'est terminé le 16 ocotbre 2021. \n",
        "\n",
        "Il portait sur la détection de la présence d'un marqueur biologique significatif dans le traitement du cancer du cerveau. \n",
        "\n",
        "[Le dataset fourni](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data) regroupe un ensemble de clichés issu d'IRM réalisés sur des cohortes ed patients.\n",
        "\n",
        "Le [kernel Kaggle que j'ai soumis](https://www.kaggle.com/cedricsoares/tf-efficientnet-transfer-learning-strat-split) pour la compétition se base sur [celui](https://www.kaggle.com/billqi/efficientnet-transfer-learning-model-full) partagé par [Bill Qi](https://www.kaggle.com/billqi).\n",
        "\n",
        "À l'issu du concours les travaux m'ont permis d'atteindre la troisème place du [classement général](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/leaderboard) avec une AUC de 0.61732."
      ],
      "id": "jhnBp0c12DeR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtjHWGHF9Ew6"
      },
      "source": [
        "## Modèle et hypothèse de prédiction"
      ],
      "id": "NtjHWGHF9Ew6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2MVWm5Q9Lo7"
      },
      "source": [
        "EfficientNet-B3 a été utilisé pour le concours. \n",
        "\n",
        "Pour chaque patient quatre types différents de clichés d'IRM ont été référencés dans le dataset (flair, t1w, t1wce, t2w).\n",
        "\n",
        "Un modèle différent a été entrâiné par type de cliché. Chaque modèle retournait la probabilité de présence du biomarqueur. \n",
        "\n",
        "La prédiction finale est obtenue par aggrégation des résultat par patient. L'équart entre la probabilité la plus haute et la moyenne des probabilités sur les différents modèles  est comparée à l'équart entre la moyenne et la probabilité la plus faible la plus faible. La probabilité liée au plus grand écart est retenue."
      ],
      "id": "X2MVWm5Q9Lo7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2o9X4Oy8LkQ"
      },
      "source": [
        "## Amélioration apportées au kernel initial "
      ],
      "id": "T2o9X4Oy8LkQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0hViv_J8SIj"
      },
      "source": [
        "Plusieurs ajouts et modifications lui ont été apporté:\n",
        "* Ajout d'une partition train / validation stratifiée par patient et classe de présence du biomarqueur.\n",
        "\n",
        "\n",
        "* Modification de la résolution de 224 x 224 à 300 x 300 afin de se mettre en conformité avec la résolution utilisée lors de l'entrainement initial du modèle\n",
        "Entrainement des modèles sur 20 epochs au lieu de 5.\n",
        "\n",
        "* Ajout d'une couche supplémentaire de batch normalization et de drop out au niveaux des couches totalement connectées.\n",
        "\n",
        "* Modification du niveau de drop out sur la couche existante (0.1 à 0.4).\n",
        "\n",
        "\n",
        "* Ajout d'un callback d'early stopping afin d'arrêter l'entraînement des modèles si la fonction de coût ne minimise plus sur le jeu de validation pendant 5 epochs.\n",
        "\n",
        "\n",
        "* Ajout d'un callback de réduction du learning rate si la fonction de coût ne minise plus sur le jeu de validation pendant 2 epochs.\n",
        "\n",
        "\n",
        "* Plusieurs valeurs de batch size ont été évalue (32, 64, 128, 256, 512) vs 512 dans le kernel initial. La valeur 128 a été retenue. "
      ],
      "id": "S0hViv_J8SIj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcX6DOhEMDbK"
      },
      "source": [
        "## Éléments à récupérer sur Kaggle:\n",
        "\n",
        "* [Données](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data?select=train_labels.csv):  (136.85 GB, ne peut être contenu dans une VM Google Colab ou Colab+)\n",
        "\n",
        "\n",
        "- [Poids du modèle pé-entraîné](https://www.kaggle.com/pansofluck/efficentnet-b0b5-tensorflow-24-notop?select=efficientnet-b3_tf24_imagenet_1000_notop.h5) :  (43.95 MB)"
      ],
      "id": "TcX6DOhEMDbK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAgyELsgAS5X"
      },
      "source": [
        "## Initialisation du projet"
      ],
      "id": "pAgyELsgAS5X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULo_-m85Ah2-",
        "outputId": "ac49f937-9e20-4c1d-cdb0-3635b485df88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ULo_-m85Ah2-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRMlouyAxDQ",
        "outputId": "6e1b5a19-9257-405b-d963-7a3118d5f44f"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "nYRMlouyAxDQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "     |████████████████████████████████| 58 kB 4.0 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (2.10)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72857 sha256=c88ff5936fa7b5040ef99aa84d18a5771c4fdd8ea2ab5dfa28493b52d3482743\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/e7/e7/eb3c3d514c33294d77ddd5a856bdd58dc9c1fabbed59a02a2b\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-10-14T16:44:54.834610Z",
          "iopub.status.busy": "2021-10-14T16:44:54.833119Z",
          "iopub.status.idle": "2021-10-14T16:45:00.804014Z",
          "shell.execute_reply": "2021-10-14T16:45:00.803391Z",
          "shell.execute_reply.started": "2021-10-14T15:19:58.743189Z"
        },
        "papermill": {
          "duration": 5.989963,
          "end_time": "2021-10-14T16:45:00.804175",
          "exception": false,
          "start_time": "2021-10-14T16:44:54.814212",
          "status": "completed"
        },
        "tags": [],
        "id": "a5ff8829"
      },
      "source": [
        "import math\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import random\n",
        "#from random import sample\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image.dataframe_iterator import DataFrameIterator\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.layers import InputLayer, GlobalAveragePooling2D, BatchNormalization, Dense, Dropout, Flatten, Conv2D, MaxPooling2D \n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import pydicom\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "root_dir = <path_dossier_dataset>\n",
        "df = pd.read_csv(root_dir+'train_labels.csv')"
      ],
      "id": "a5ff8829",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcyZ7xg9OZc_"
      },
      "source": [
        "### Ajout du chemin d'accès de chaque fichier dans le dataframe"
      ],
      "id": "jcyZ7xg9OZc_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:00.897552Z",
          "iopub.status.busy": "2021-10-14T16:45:00.883497Z",
          "iopub.status.idle": "2021-10-14T16:45:00.899361Z",
          "shell.execute_reply": "2021-10-14T16:45:00.899781Z",
          "shell.execute_reply.started": "2021-10-14T15:20:03.964295Z"
        },
        "papermill": {
          "duration": 0.034489,
          "end_time": "2021-10-14T16:45:00.899899",
          "exception": false,
          "start_time": "2021-10-14T16:45:00.865410",
          "status": "completed"
        },
        "tags": [],
        "id": "0179912a"
      },
      "source": [
        "# Add the full paths for each id for different types of sequences to the csv \n",
        "def full_ids(data):\n",
        "    zeros = 5 - len(str(data))\n",
        "    if zeros > 0:\n",
        "        prefix = ''.join(['0' for i in range(zeros)])\n",
        "    \n",
        "    return prefix+str(data)\n",
        "        \n",
        "\n",
        "df['BraTS21ID_full'] = df['BraTS21ID'].apply(full_ids)\n",
        "\n",
        "# Add all the paths to the df for easy access\n",
        "df['flair'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/FLAIR/')\n",
        "df['t1w'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T1w/')\n",
        "df['t1wce'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T1wCE/')\n",
        "df['t2w'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T2w/')"
      ],
      "id": "0179912a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:00.930879Z",
          "iopub.status.busy": "2021-10-14T16:45:00.930363Z",
          "iopub.status.idle": "2021-10-14T16:45:00.943242Z",
          "shell.execute_reply": "2021-10-14T16:45:00.942826Z",
          "shell.execute_reply.started": "2021-10-14T15:20:03.986404Z"
        },
        "papermill": {
          "duration": 0.030782,
          "end_time": "2021-10-14T16:45:00.943346",
          "exception": false,
          "start_time": "2021-10-14T16:45:00.912564",
          "status": "completed"
        },
        "tags": [],
        "id": "92001b19"
      },
      "source": [
        "df_test = pd.read_csv(root_dir+'sample_submission.csv')\n",
        "\n",
        "df_test['BraTS21ID_full'] = df_test['BraTS21ID'].apply(full_ids)\n",
        "\n",
        "# Add all the paths to the df for easy access\n",
        "df_test['flair'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/FLAIR/')\n",
        "df_test['t1w'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T1w/')\n",
        "df_test['t1wce'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T1wCE/')\n",
        "df_test['t2w'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T2w/')"
      ],
      "id": "92001b19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.012879,
          "end_time": "2021-10-14T16:45:00.968995",
          "exception": false,
          "start_time": "2021-10-14T16:45:00.956116",
          "status": "completed"
        },
        "tags": [],
        "id": "7a24d0d7"
      },
      "source": [
        "## Chargement des images\n"
      ],
      "id": "7a24d0d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu-fZYogQYfj"
      },
      "source": [
        "### Construction de dataframes de partition train, validation, test"
      ],
      "id": "tu-fZYogQYfj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT5EK9wHOnFv"
      },
      "source": [
        "Certaines données ont été identifiés comme partiellement complètes par organisateurs du concours. :\n",
        "\n",
        "* Patient 00109 (FLAIR: clichés manquants)\n",
        "* Patient 00123 (T1w:  clichés manquants)\n",
        "* Patient 00709 (FLAIR: clichés manquants)\n",
        "\n",
        "Le dataframe initial est reformaté afin d'obtenir des dataframes spécifiques pour chaque partition train, validation, test.\n",
        "\n",
        "Il seront utilisés dans un itérateur appelé pour générer les batch et y appliquer la data augmentation.\n",
        "\n",
        "Initailement les données sont partitionnées entre train et test.\n",
        "Pour le projet une partition de validation supplémentaire a été crée à partir de la partition train. \n",
        "\n",
        "La partition 90% train / 10% validation a été réalisée de manière stratifiée sur les numéros de patients et par classe. "
      ],
      "id": "cT5EK9wHOnFv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.014725Z",
          "iopub.status.busy": "2021-10-14T16:45:01.003586Z",
          "iopub.status.idle": "2021-10-14T16:45:01.017066Z",
          "shell.execute_reply": "2021-10-14T16:45:01.016619Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.006699Z"
        },
        "papermill": {
          "duration": 0.035264,
          "end_time": "2021-10-14T16:45:01.017174",
          "exception": false,
          "start_time": "2021-10-14T16:45:00.981910",
          "status": "completed"
        },
        "tags": [],
        "id": "c69bb787"
      },
      "source": [
        "def get_train_val_dataframe(mri_type):\n",
        "    \n",
        "    all_img_files = []\n",
        "    all_img_labels = []\n",
        "    all_img_patient_ids = []\n",
        "    for row in df.iterrows():\n",
        "        if row[1]['BraTS21ID_full'] == '00109' and mri_type == 'flair':\n",
        "            continue\n",
        "        if row[1]['BraTS21ID_full'] == '00123' and mri_type == 't1w':\n",
        "            continue\n",
        "        if row[1]['BraTS21ID_full'] == '00709' and mri_type == 'flair':\n",
        "            continue\n",
        "        img_dir = row[1][mri_type]\n",
        "        img_files = os.listdir(img_dir)\n",
        "        img_nums = sorted([int(ele.replace('Image-', '').replace('.dcm', '')) for ele in img_files])\n",
        "        mid_point = int(len(img_nums)/2)\n",
        "        start_point = mid_point - max(int(mid_point*0.1), 1)\n",
        "        end_point = mid_point + max(int(mid_point*0.1), 1)\n",
        "        img_names = [f'Image-{img_nums[i]}.dcm' for i in range(start_point, end_point+1)]\n",
        "        img_paths = [img_dir+ele for ele in img_names]\n",
        "        img_labels = [row[1]['MGMT_value']]*len(img_paths)\n",
        "        img_patient_ids = [row[1]['BraTS21ID']]*len(img_paths)\n",
        "        all_img_files.extend(img_paths)\n",
        "        all_img_labels.extend(img_labels)\n",
        "        all_img_patient_ids.extend(img_patient_ids)\n",
        "\n",
        "    train_val_df = pd.DataFrame({'patient_ids': all_img_patient_ids,\n",
        "                  'labels': all_img_labels,\n",
        "                  'file_paths': all_img_files})\n",
        "\n",
        "    train_val_df['labels'] = train_val_df['labels'].map({1: '1', 0: '0'})\n",
        "    \n",
        "    #stratifiied 90% split on patient_ids and labels  \n",
        "    class_prop= 0.90\n",
        "    \n",
        "    classes_splits  = {}\n",
        "    for i in range(2):\n",
        "        train_val_label_class = train_val_df[train_val_df['labels']==f'{i}']\n",
        "        train_val_list_ids =  list(train_val_label_class['patient_ids'].unique())\n",
        "        train_threshold = math.ceil(class_prop*len(train_val_list_ids))\n",
        "        train_ids = train_val_list_ids[:train_threshold]\n",
        "        val_ids = train_val_list_ids[train_threshold:]\n",
        "        classes_splits[f'train_{i}'] = train_val_label_class[train_val_label_class['patient_ids'].isin(train_ids)]\n",
        "        classes_splits[f'val_{i}'] = val_df = train_val_label_class[train_val_label_class['patient_ids'].isin(val_ids)]\n",
        "        \n",
        "    train_df = pd.concat([classes_splits['train_0'], classes_splits['train_1']], axis=0)\n",
        "    val_df = pd.concat([classes_splits['val_0'], classes_splits['val_1']], axis=0)\n",
        "  \n",
        "    return train_df, val_df\n",
        "    \n",
        "def get_test_dataframe(mri_type):\n",
        "    \n",
        "    all_test_img_files = []\n",
        "    all_test_img_labels = []\n",
        "    all_test_img_patient_ids = []\n",
        "    for row in df_test.iterrows():\n",
        "        img_dir = row[1][mri_type]\n",
        "        img_files = os.listdir(img_dir)\n",
        "        img_nums = sorted([int(ele.replace('Image-', '').replace('.dcm', '')) for ele in img_files])\n",
        "        mid_point = int(len(img_nums)/2)\n",
        "        start_point = mid_point - max(int(mid_point*0.1), 1)\n",
        "        end_point = mid_point + max(int(mid_point*0.1), 1)\n",
        "        img_names = [f'Image-{img_nums[i]}.dcm' for i in range(start_point, end_point+1)]\n",
        "        img_paths = [img_dir+ele for ele in img_names]\n",
        "        img_labels = [row[1]['MGMT_value']]*len(img_paths)\n",
        "        img_patient_ids = [row[1]['BraTS21ID']]*len(img_paths)\n",
        "        all_test_img_files.extend(img_paths)\n",
        "        all_test_img_labels.extend(img_labels)\n",
        "        all_test_img_patient_ids.extend(img_patient_ids)\n",
        "\n",
        "    test_df = pd.DataFrame({'patient_ids': all_test_img_patient_ids,\n",
        "                  'labels': all_test_img_labels,\n",
        "                  'file_paths': all_test_img_files})\n",
        "    \n",
        "    test_df['labels'] = ['1']*(len(test_df)-1) + ['0'] # workaround for testing data gen\n",
        "    \n",
        "    return test_df"
      ],
      "id": "c69bb787",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Yaa6c8QhJB"
      },
      "source": [
        "### Création de l'itérateur"
      ],
      "id": "56Yaa6c8QhJB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syO-IgbjQnWu"
      },
      "source": [
        "L'itérateur est construit par héritage de la classe DataFrameIterator fournie par l'implémentation TensorFlow de Keras.\n",
        "\n",
        "Dans la classe itérateur, une méthode spécifique est implémentée pour réaliser le pré-traitement des images. Un normailisation min-max est appliqué aux images."
      ],
      "id": "syO-IgbjQnWu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.054581Z",
          "iopub.status.busy": "2021-10-14T16:45:01.053759Z",
          "iopub.status.idle": "2021-10-14T16:45:01.056092Z",
          "shell.execute_reply": "2021-10-14T16:45:01.055573Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.028702Z"
        },
        "papermill": {
          "duration": 0.026322,
          "end_time": "2021-10-14T16:45:01.056197",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.029875",
          "status": "completed"
        },
        "tags": [],
        "id": "39d9f56e"
      },
      "source": [
        "class DCMDataFrameIterator(DataFrameIterator):\n",
        "    def __init__(self, *arg, **kwargs):\n",
        "        self.white_list_formats = ('dcm')\n",
        "        super(DCMDataFrameIterator, self).__init__(*arg, **kwargs)\n",
        "        self.dataframe = kwargs['dataframe']\n",
        "        self.x = self.dataframe[kwargs['x_col']]\n",
        "        self.y = self.dataframe[kwargs['y_col']]\n",
        "        self.color_mode = kwargs['color_mode']\n",
        "        self.target_size = kwargs['target_size']\n",
        "\n",
        "    def _get_batches_of_transformed_samples(self, indices_array):\n",
        "        # get batch of images\n",
        "        batch_x = np.array([self.read_dcm_as_array(dcm_path, self.target_size, color_mode=self.color_mode)\n",
        "                            for dcm_path in self.x.iloc[indices_array]])\n",
        "\n",
        "        batch_y = np.array(self.y.iloc[indices_array].astype(np.uint8))  # astype because y was passed as str\n",
        "\n",
        "        # transform images\n",
        "        if self.image_data_generator is not None:\n",
        "            for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n",
        "                transform_params = self.image_data_generator.get_random_transform(x.shape)\n",
        "                batch_x[i] = self.image_data_generator.apply_transform(x, transform_params)\n",
        "                # you can change y here as well, eg: in semantic segmentation you want to transform masks as well \n",
        "                # using the same image_data_generator transformations.\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    @staticmethod\n",
        "    def read_dcm_as_array(dcm_path, target_size=(300, 300), color_mode='rgb'):\n",
        "        image_array = pydicom.dcmread(dcm_path).pixel_array\n",
        "        pixels = image_array - np.min(image_array)\n",
        "        pixels = pixels / np.max(pixels)\n",
        "        image_manual_norm = (pixels * 255).astype(np.uint8)\n",
        "        image_array = cv2.resize(image_manual_norm, target_size, interpolation=cv2.INTER_NEAREST)  #this returns a 2d array\n",
        "#         image_array = np.expand_dims(image_array, -1)\n",
        "        if color_mode == 'rgb':\n",
        "            image_array = np.dstack((image_array, np.zeros_like(image_array), np.zeros_like(image_array)))\n",
        "        return image_array"
      ],
      "id": "39d9f56e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rl7FeSDRZZA"
      },
      "source": [
        "## Data augmentation "
      ],
      "id": "4Rl7FeSDRZZA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttg8ETsXRoKs"
      },
      "source": [
        "La clase ImageDataGenerator de l'API Keras/TensorFlow est utillisée pour générer des batch de 128 images.\n",
        "\n",
        "Les valeurs des pixels des images sont normalisées à une échelle 0 à 1 sur tout les jeux de donées.\n",
        "\n",
        "Sur le jeu train plusieurs transformations de data augmentation sont appliquées:\n",
        "* zoom\n",
        "* rotation\n",
        "* décalage vertical\n",
        "* décalage horizontal\n",
        "* retournement horizontal\n",
        "* modification de la luminosité"
      ],
      "id": "ttg8ETsXRoKs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.124572Z",
          "iopub.status.busy": "2021-10-14T16:45:01.123791Z",
          "iopub.status.idle": "2021-10-14T16:45:01.126177Z",
          "shell.execute_reply": "2021-10-14T16:45:01.125755Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.054446Z"
        },
        "papermill": {
          "duration": 0.024563,
          "end_time": "2021-10-14T16:45:01.126274",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.101711",
          "status": "completed"
        },
        "tags": [],
        "id": "8fecf329"
      },
      "source": [
        "SEED = 369\n",
        "BATCH_SIZE = 128\n",
        "CLASS_MODE = 'binary'\n",
        "COLOR_MODE = 'rgb'\n",
        "TARGET_SIZE = (300, 300)\n",
        "\n",
        "def get_data_generators(train_df,val_df, test_df):\n",
        "    train_augmentation_parameters = dict(\n",
        "        rescale=1.0/255,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=0.2,\n",
        "        fill_mode='nearest',\n",
        "        height_shift_range= 0.1,\n",
        "        width_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range = [0.8, 1.2]\n",
        "    )\n",
        "    \n",
        "    val_augmentation_parameters = dict(\n",
        "        rescale=1.0/255.0\n",
        "    )\n",
        "\n",
        "    test_augmentation_parameters = dict(\n",
        "        rescale=1.0/255.0\n",
        "    )\n",
        "\n",
        "    train_consts = {\n",
        "        'seed': SEED,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'class_mode': CLASS_MODE,\n",
        "        'color_mode': COLOR_MODE,\n",
        "        'target_size': TARGET_SIZE,  \n",
        "    }\n",
        "    \n",
        "    val_consts = {\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'class_mode': CLASS_MODE,\n",
        "    'color_mode': COLOR_MODE,\n",
        "    'target_size': TARGET_SIZE,\n",
        "    'shuffle': False\n",
        "    }\n",
        "\n",
        "    test_consts = {\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'class_mode': CLASS_MODE,\n",
        "        'color_mode': COLOR_MODE,\n",
        "        'target_size': TARGET_SIZE,\n",
        "        'shuffle': False\n",
        "    }\n",
        "\n",
        "    train_augmenter = ImageDataGenerator(**train_augmentation_parameters)\n",
        "    val_augmenter = ImageDataGenerator(**val_augmentation_parameters)\n",
        "    test_augmenter = ImageDataGenerator(**test_augmentation_parameters)\n",
        "\n",
        "    train_generator = DCMDataFrameIterator(dataframe=train_df,\n",
        "                                 x_col='file_paths',\n",
        "                                 y_col='labels',\n",
        "                                 image_data_generator=train_augmenter,\n",
        "                                 **train_consts)\n",
        "    \n",
        "    val_generator = DCMDataFrameIterator(dataframe=val_df,\n",
        "                                 x_col='file_paths',\n",
        "                                 y_col='labels',\n",
        "                                 image_data_generator=val_augmenter,\n",
        "                                 **val_consts)\n",
        "    \n",
        "    test_generator = DCMDataFrameIterator(dataframe=test_df,\n",
        "                                 x_col='file_paths',\n",
        "                                 y_col='labels',\n",
        "                                 image_data_generator=test_augmenter,\n",
        "                                 **test_consts)\n",
        "    \n",
        "    return train_generator, val_generator, test_generator"
      ],
      "id": "8fecf329",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.012648,
          "end_time": "2021-10-14T16:45:01.151649",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.139001",
          "status": "completed"
        },
        "tags": [],
        "id": "de17d813"
      },
      "source": [
        "## Construction et entrâinement du modèle"
      ],
      "id": "de17d813"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aax9zlk5SuZw"
      },
      "source": [
        "### Fonction construction du modèle "
      ],
      "id": "aax9zlk5SuZw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Ek7gVFS4eu"
      },
      "source": [
        "Les couches convolutionnelles d'EfficientNetB3 sont gelées. Une batch normalization pour favoriser la convergence du modèle et un drop out de 40% pour éviter le surapprentissage sont ajoutées avant chaque couche totalement connectée.\n",
        "\n",
        "Pour répondre au problème de classification bi-classes la fonction d'activation sigmoïd est utilisée sur la dernière couche. De la même manière, la binary-crossentropy est utilisée comme fonction de coût.\n",
        "\n",
        "Un optimizer Adam est utilisé avec un learning rate fixé à 0.001"
      ],
      "id": "Z0Ek7gVFS4eu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.184027Z",
          "iopub.status.busy": "2021-10-14T16:45:01.183280Z",
          "iopub.status.idle": "2021-10-14T16:45:01.185231Z",
          "shell.execute_reply": "2021-10-14T16:45:01.185623Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.069299Z"
        },
        "papermill": {
          "duration": 0.021384,
          "end_time": "2021-10-14T16:45:01.185760",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.164376",
          "status": "completed"
        },
        "tags": [],
        "id": "23771dcb"
      },
      "source": [
        "def build_model(weights_path):\n",
        "    \n",
        "    model = EfficientNetB3(include_top=False, weights=weights_path)\n",
        "    \n",
        "    model.trainable = False\n",
        "    \n",
        "    x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.4\n",
        "    x = Dropout(top_dropout_rate)(x)\n",
        "    x = Dense(32, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(top_dropout_rate)(x)\n",
        "    outputs = Dense(1, activation=\"sigmoid\", name=\"pred\")(x)\n",
        "    \n",
        "\n",
        "    # Compile\n",
        "    model = Model(model.inputs, outputs, name=\"EfficientNet\")\n",
        "    \n",
        "\n",
        "    # Compile\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\",AUC()])\n",
        "    return model"
      ],
      "id": "23771dcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9opERbT5B3"
      },
      "source": [
        "### Fnoction d'entraînement"
      ],
      "id": "1b9opERbT5B3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CYmNiP2T-Dl"
      },
      "source": [
        "La fonction permet d'appeler la fonction de construction du modèle avec le chargement des poids pré-entraînés. Elle permet également de définir les callback de sauvegarde du modèle, d'early stopping et de réduction du learning rate."
      ],
      "id": "9CYmNiP2T-Dl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.218975Z",
          "iopub.status.busy": "2021-10-14T16:45:01.218201Z",
          "iopub.status.idle": "2021-10-14T16:45:01.220181Z",
          "shell.execute_reply": "2021-10-14T16:45:01.220573Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.079270Z"
        },
        "papermill": {
          "duration": 0.022038,
          "end_time": "2021-10-14T16:45:01.220696",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.198658",
          "status": "completed"
        },
        "tags": [],
        "id": "0eb59d0a"
      },
      "source": [
        "checkpoint_filepath = 'best_model.h5'\n",
        "\n",
        "def train_model(model_name, train_generator, val_generator, epochs):\n",
        "    \n",
        "    print('training', model_name)\n",
        "    path_model = <path_du_model>\n",
        "    model = build_model(path_model + \"/efficientnet-b3_tf24_imagenet_1000_notop.h5\")\n",
        "    \n",
        "    #callbacks\n",
        "    \n",
        "    checkpoint_cb=ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=False,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        save_freq='epoch',\n",
        "        verbose=1)\n",
        "    \n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                  patience=5,\n",
        "                                                  mode='min',\n",
        "                                                  verbose=1,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "    reduce_lr_cb=ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                                   patience=2, min_lr=0.00001,\n",
        "                                  verbose=1)\n",
        "\n",
        "    history = model.fit(\n",
        "                        train_generator,\n",
        "                        steps_per_epoch=len(train_generator),\n",
        "                        validation_data=val_generator,\n",
        "                        validation_steps=len(val_generator),\n",
        "                        epochs=epochs,\n",
        "                        workers=2,\n",
        "                        callbacks=[checkpoint_cb, reduce_lr_cb, early_stopping_cb]\n",
        "                        )\n",
        "\n",
        "    return model"
      ],
      "id": "0eb59d0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNMSivkpUX-V"
      },
      "source": [
        "### Entrainement du modèle"
      ],
      "id": "zNMSivkpUX-V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ei9g6YUf6Q"
      },
      "source": [
        "Pour chaque type de cliché un modèle est entraîné sur 20 epochs au maximum.\n",
        "Seul un résultat de modèle est retenu par patient. Comme indiqué en préambule, le sélection se fait entre le modèle donnant la prédiction la plus basse à celui donnant la prédiction la plus haute."
      ],
      "id": "x0ei9g6YUf6Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T16:45:01.252846Z",
          "iopub.status.busy": "2021-10-14T16:45:01.252205Z",
          "iopub.status.idle": "2021-10-14T18:43:09.420352Z",
          "shell.execute_reply": "2021-10-14T18:43:09.420824Z",
          "shell.execute_reply.started": "2021-10-14T15:20:04.089817Z"
        },
        "papermill": {
          "duration": 7088.188432,
          "end_time": "2021-10-14T18:43:09.421938",
          "exception": false,
          "start_time": "2021-10-14T16:45:01.233506",
          "status": "completed"
        },
        "tags": [],
        "id": "9ea9cb0e",
        "outputId": "48a8253a-4a0e-4bf0-9979-c48f1dd14a9f"
      },
      "source": [
        "%%time\n",
        "# train a model for each of the mri types and then ensemble predictions\n",
        "all_test_preds = []\n",
        "\n",
        "for mt in ['flair', 't1w', 't1wce', 't2w']:\n",
        "    train_df, val_df = get_train_val_dataframe(mt)\n",
        "    test_df = get_test_dataframe(mt)\n",
        "    train_g, val_g, test_g = get_data_generators(train_df, val_df, test_df)\n",
        "    best_model =  train_model(mt, train_g, val_g, epochs=20)\n",
        "    results = best_model.evaluate(test_g, steps=len(test_g))\n",
        "    print(f\"test loss, test acc, test AUC: {results}\")\n",
        "    test_pred = best_model.predict(test_g, steps=len(test_g))\n",
        "    test_df['pred_y'] = test_pred\n",
        "    # aggregate the predictions on all image for each person (take the most confident prediction out of all image predictions)\n",
        "    mean_pred = test_pred.mean()\n",
        "    test_pred_agg = test_df.groupby('patient_ids').apply(\n",
        "        lambda x: x['pred_y'].max()\n",
        "        if (x['pred_y'].max() - mean_pred) > (mean_pred - x['pred_y'].min()) \n",
        "        else x['pred_y'].min())\n",
        "    all_test_preds.append(test_pred_agg.values)"
      ],
      "id": "9ea9cb0e",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7306 validated image filenames belonging to 2 classes.\n",
            "Found 333 validated image filenames belonging to 2 classes.\n",
            "Found 1119 validated image filenames belonging to 2 classes.\n",
            "training flair\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-14 16:45:11.794762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:11.884834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:11.885514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:11.886627: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-10-14 16:45:11.887631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:11.888335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:11.888963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:13.750941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:13.751804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:13.752443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-14 16:45:13.753158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "2021-10-14 16:45:22.090119: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-10-14 16:45:36.556782: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58/58 [==============================] - 180s 3s/step - loss: 0.8365 - binary_accuracy: 0.5506 - auc: 0.5626 - val_loss: 0.6928 - val_binary_accuracy: 0.5465 - val_auc: 0.5861\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69276, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/20\n",
            "58/58 [==============================] - 149s 3s/step - loss: 0.7228 - binary_accuracy: 0.5935 - auc: 0.6142 - val_loss: 0.6883 - val_binary_accuracy: 0.5916 - val_auc: 0.5936\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69276 to 0.68835, saving model to best_model.h5\n",
            "Epoch 3/20\n",
            "58/58 [==============================] - 148s 3s/step - loss: 0.6913 - binary_accuracy: 0.6095 - auc: 0.6295 - val_loss: 0.6815 - val_binary_accuracy: 0.5796 - val_auc: 0.5852\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68835 to 0.68147, saving model to best_model.h5\n",
            "Epoch 4/20\n",
            "58/58 [==============================] - 150s 2s/step - loss: 0.6674 - binary_accuracy: 0.6248 - auc: 0.6492 - val_loss: 0.6810 - val_binary_accuracy: 0.5916 - val_auc: 0.6023\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.68147 to 0.68100, saving model to best_model.h5\n",
            "Epoch 5/20\n",
            "58/58 [==============================] - 150s 3s/step - loss: 0.6535 - binary_accuracy: 0.6304 - auc: 0.6633 - val_loss: 0.6883 - val_binary_accuracy: 0.5796 - val_auc: 0.5721\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68100\n",
            "Epoch 6/20\n",
            "58/58 [==============================] - 151s 3s/step - loss: 0.6436 - binary_accuracy: 0.6388 - auc: 0.6700 - val_loss: 0.6731 - val_binary_accuracy: 0.6096 - val_auc: 0.6287\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.68100 to 0.67313, saving model to best_model.h5\n",
            "Epoch 7/20\n",
            "58/58 [==============================] - 150s 3s/step - loss: 0.6275 - binary_accuracy: 0.6484 - auc: 0.6888 - val_loss: 0.6758 - val_binary_accuracy: 0.6306 - val_auc: 0.6300\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.67313\n",
            "Epoch 8/20\n",
            "58/58 [==============================] - 150s 3s/step - loss: 0.6239 - binary_accuracy: 0.6517 - auc: 0.6942 - val_loss: 0.6797 - val_binary_accuracy: 0.5886 - val_auc: 0.6092\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.67313\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 9/20\n",
            "58/58 [==============================] - 153s 3s/step - loss: 0.6160 - binary_accuracy: 0.6590 - auc: 0.7039 - val_loss: 0.6734 - val_binary_accuracy: 0.6066 - val_auc: 0.6238\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.67313\n",
            "Epoch 10/20\n",
            "58/58 [==============================] - 148s 3s/step - loss: 0.6152 - binary_accuracy: 0.6559 - auc: 0.7008 - val_loss: 0.6869 - val_binary_accuracy: 0.5676 - val_auc: 0.5904\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.67313\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 11/20\n",
            "58/58 [==============================] - 155s 3s/step - loss: 0.6079 - binary_accuracy: 0.6692 - auc: 0.7163 - val_loss: 0.6897 - val_binary_accuracy: 0.5826 - val_auc: 0.5902\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.67313\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "9/9 [==============================] - 12s 1s/step - loss: 0.5552 - binary_accuracy: 0.7551 - auc: 0.4580\n",
            "test loss, test acc, test AUC: [0.5552219152450562, 0.7551385164260864, 0.45796066522598267]\n",
            "Found 7347 validated image filenames belonging to 2 classes.\n",
            "Found 389 validated image filenames belonging to 2 classes.\n",
            "Found 1187 validated image filenames belonging to 2 classes.\n",
            "training t1w\n",
            "Epoch 1/20\n",
            "58/58 [==============================] - 176s 3s/step - loss: 0.7882 - binary_accuracy: 0.5425 - auc_1: 0.5602 - val_loss: 0.6743 - val_binary_accuracy: 0.5835 - val_auc_1: 0.6135\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67429, saving model to best_model.h5\n",
            "Epoch 2/20\n",
            "58/58 [==============================] - 148s 3s/step - loss: 0.7216 - binary_accuracy: 0.5789 - auc_1: 0.5975 - val_loss: 0.6680 - val_binary_accuracy: 0.5810 - val_auc_1: 0.6287\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67429 to 0.66798, saving model to best_model.h5\n",
            "Epoch 3/20\n",
            "58/58 [==============================] - 147s 2s/step - loss: 0.6961 - binary_accuracy: 0.5925 - auc_1: 0.6200 - val_loss: 0.6708 - val_binary_accuracy: 0.5578 - val_auc_1: 0.6193\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.66798\n",
            "Epoch 4/20\n",
            "58/58 [==============================] - 152s 3s/step - loss: 0.6769 - binary_accuracy: 0.5924 - auc_1: 0.6324 - val_loss: 0.6738 - val_binary_accuracy: 0.5501 - val_auc_1: 0.6055\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.66798\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 5/20\n",
            "58/58 [==============================] - 148s 2s/step - loss: 0.6664 - binary_accuracy: 0.6030 - auc_1: 0.6431 - val_loss: 0.6813 - val_binary_accuracy: 0.5553 - val_auc_1: 0.5802\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.66798\n",
            "Epoch 6/20\n",
            "58/58 [==============================] - 149s 2s/step - loss: 0.6578 - binary_accuracy: 0.6133 - auc_1: 0.6578 - val_loss: 0.6831 - val_binary_accuracy: 0.5424 - val_auc_1: 0.5777\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.66798\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 7/20\n",
            "58/58 [==============================] - 150s 2s/step - loss: 0.6461 - binary_accuracy: 0.6226 - auc_1: 0.6716 - val_loss: 0.6880 - val_binary_accuracy: 0.5296 - val_auc_1: 0.5745\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.66798\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00007: early stopping\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.5861 - binary_accuracy: 0.8222 - auc_1: 0.2989\n",
            "test loss, test acc, test AUC: [0.5861029028892517, 0.822240948677063, 0.2989038825035095]\n",
            "Found 9312 validated image filenames belonging to 2 classes.\n",
            "Found 387 validated image filenames belonging to 2 classes.\n",
            "Found 1441 validated image filenames belonging to 2 classes.\n",
            "training t1wce\n",
            "Epoch 1/20\n",
            "73/73 [==============================] - 224s 3s/step - loss: 0.8811 - binary_accuracy: 0.5450 - auc_2: 0.5548 - val_loss: 0.7071 - val_binary_accuracy: 0.4599 - val_auc_2: 0.5737\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.70707, saving model to best_model.h5\n",
            "Epoch 2/20\n",
            "73/73 [==============================] - 185s 2s/step - loss: 0.7551 - binary_accuracy: 0.5735 - auc_2: 0.5960 - val_loss: 0.7017 - val_binary_accuracy: 0.4987 - val_auc_2: 0.5566\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.70707 to 0.70166, saving model to best_model.h5\n",
            "Epoch 3/20\n",
            "73/73 [==============================] - 190s 3s/step - loss: 0.7209 - binary_accuracy: 0.5869 - auc_2: 0.6131 - val_loss: 0.6920 - val_binary_accuracy: 0.5556 - val_auc_2: 0.5578\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.70166 to 0.69196, saving model to best_model.h5\n",
            "Epoch 4/20\n",
            "73/73 [==============================] - 188s 3s/step - loss: 0.6942 - binary_accuracy: 0.5916 - auc_2: 0.6234 - val_loss: 0.6930 - val_binary_accuracy: 0.5245 - val_auc_2: 0.5590\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.69196\n",
            "Epoch 5/20\n",
            "73/73 [==============================] - 189s 3s/step - loss: 0.6719 - binary_accuracy: 0.6142 - auc_2: 0.6473 - val_loss: 0.7004 - val_binary_accuracy: 0.5013 - val_auc_2: 0.5420\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.69196\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 6/20\n",
            "73/73 [==============================] - 193s 3s/step - loss: 0.6595 - binary_accuracy: 0.6193 - auc_2: 0.6595 - val_loss: 0.7080 - val_binary_accuracy: 0.5168 - val_auc_2: 0.5500\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.69196\n",
            "Epoch 7/20\n",
            "73/73 [==============================] - 191s 3s/step - loss: 0.6504 - binary_accuracy: 0.6271 - auc_2: 0.6741 - val_loss: 0.7155 - val_binary_accuracy: 0.5090 - val_auc_2: 0.5601\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.69196\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 8/20\n",
            "73/73 [==============================] - 190s 3s/step - loss: 0.6475 - binary_accuracy: 0.6276 - auc_2: 0.6728 - val_loss: 0.7149 - val_binary_accuracy: 0.5349 - val_auc_2: 0.5665\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.69196\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00008: early stopping\n",
            "12/12 [==============================] - 17s 1s/step - loss: 0.6760 - binary_accuracy: 0.5961 - auc_2: 0.9135\n",
            "test loss, test acc, test AUC: [0.6760003566741943, 0.5961138010025024, 0.9135416746139526]\n",
            "Found 9830 validated image filenames belonging to 2 classes.\n",
            "Found 325 validated image filenames belonging to 2 classes.\n",
            "Found 1463 validated image filenames belonging to 2 classes.\n",
            "training t2w\n",
            "Epoch 1/20\n",
            " 5/77 [>.............................] - ETA: 3:30 - loss: 0.9732 - binary_accuracy: 0.5219 - auc_3: 0.5221"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77/77 [==============================] - 238s 3s/step - loss: 0.8128 - binary_accuracy: 0.5589 - auc_3: 0.5560 - val_loss: 0.6753 - val_binary_accuracy: 0.5662 - val_auc_3: 0.5724\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67526, saving model to best_model.h5\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 205s 3s/step - loss: 0.7187 - binary_accuracy: 0.6046 - auc_3: 0.6062 - val_loss: 0.6796 - val_binary_accuracy: 0.5662 - val_auc_3: 0.5686\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.67526\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 204s 3s/step - loss: 0.6896 - binary_accuracy: 0.6108 - auc_3: 0.6188 - val_loss: 0.6785 - val_binary_accuracy: 0.5631 - val_auc_3: 0.5650\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.67526\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 203s 3s/step - loss: 0.6608 - binary_accuracy: 0.6266 - auc_3: 0.6503 - val_loss: 0.6742 - val_binary_accuracy: 0.5692 - val_auc_3: 0.5860\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.67526 to 0.67417, saving model to best_model.h5\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 205s 3s/step - loss: 0.6524 - binary_accuracy: 0.6340 - auc_3: 0.6574 - val_loss: 0.6744 - val_binary_accuracy: 0.5938 - val_auc_3: 0.5888\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.67417\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 207s 3s/step - loss: 0.6376 - binary_accuracy: 0.6456 - auc_3: 0.6736 - val_loss: 0.6744 - val_binary_accuracy: 0.5815 - val_auc_3: 0.5968\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.67417\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 204s 3s/step - loss: 0.6361 - binary_accuracy: 0.6519 - auc_3: 0.6800 - val_loss: 0.6893 - val_binary_accuracy: 0.5631 - val_auc_3: 0.5852\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.67417\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 206s 3s/step - loss: 0.6276 - binary_accuracy: 0.6536 - auc_3: 0.6879 - val_loss: 0.6947 - val_binary_accuracy: 0.5692 - val_auc_3: 0.5854\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.67417\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 207s 3s/step - loss: 0.6282 - binary_accuracy: 0.6480 - auc_3: 0.6869 - val_loss: 0.6952 - val_binary_accuracy: 0.5600 - val_auc_3: 0.5885\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.67417\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "12/12 [==============================] - 21s 2s/step - loss: 0.4541 - binary_accuracy: 0.9125 - auc_3: 0.7842\n",
            "test loss, test acc, test AUC: [0.45410189032554626, 0.9125085473060608, 0.7841997146606445]\n",
            "CPU times: user 3h 1s, sys: 4min 47s, total: 3h 4min 48s\n",
            "Wall time: 1h 58min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVHUwl3_Ve3A"
      },
      "source": [
        "On constate que, globablement, la fonction de coût de chaque modèle arrête de monimiser rapidement. La réduction du learning rate n'est pas forcément efficiente."
      ],
      "id": "vVHUwl3_Ve3A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.64898,
          "end_time": "2021-10-14T18:43:10.728547",
          "exception": false,
          "start_time": "2021-10-14T18:43:10.079567",
          "status": "completed"
        },
        "tags": [],
        "id": "495e2dd1"
      },
      "source": [
        "## Soumission des résultat"
      ],
      "id": "495e2dd1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWaN6SV9Wa_p"
      },
      "source": [
        "Avant la soumission des résultats nous affichons la distribution des probabilités prédites."
      ],
      "id": "sWaN6SV9Wa_p"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T18:43:13.432421Z",
          "iopub.status.busy": "2021-10-14T18:43:13.431503Z",
          "iopub.status.idle": "2021-10-14T18:43:13.728107Z",
          "shell.execute_reply": "2021-10-14T18:43:13.727489Z",
          "shell.execute_reply.started": "2021-10-14T16:43:16.593802Z"
        },
        "papermill": {
          "duration": 1.001022,
          "end_time": "2021-10-14T18:43:13.728243",
          "exception": false,
          "start_time": "2021-10-14T18:43:12.727221",
          "status": "completed"
        },
        "tags": [],
        "id": "288f2632",
        "outputId": "a74c80d7-de00-4764-8164-b5bc6f594235"
      },
      "source": [
        "all_test_preds = np.array(all_test_preds)\n",
        "plt.hist(all_test_preds.mean(0))"
      ],
      "id": "288f2632",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([11.,  9.,  6., 13., 14.,  8.,  8.,  4.,  4., 10.]),\n",
              " array([0.3528444 , 0.39227874, 0.43171308, 0.47114742, 0.51058176,\n",
              "        0.55001611, 0.58945045, 0.62888479, 0.66831913, 0.70775347,\n",
              "        0.74718781]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T18:43:15.053960Z",
          "iopub.status.busy": "2021-10-14T18:43:15.053284Z",
          "iopub.status.idle": "2021-10-14T18:43:15.090097Z",
          "shell.execute_reply": "2021-10-14T18:43:15.089107Z",
          "shell.execute_reply.started": "2021-10-14T16:43:16.912011Z"
        },
        "papermill": {
          "duration": 0.701555,
          "end_time": "2021-10-14T18:43:15.090218",
          "exception": false,
          "start_time": "2021-10-14T18:43:14.388663",
          "status": "completed"
        },
        "tags": [],
        "id": "e846eeba"
      },
      "source": [
        "subm = pd.read_csv(root_dir+'sample_submission.csv')\n",
        "subm['MGMT_value'] = all_test_preds.mean(0)\n",
        "subm.to_csv(\"submission.csv\", index=False)"
      ],
      "id": "e846eeba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-14T18:43:16.480736Z",
          "iopub.status.busy": "2021-10-14T18:43:16.479804Z",
          "iopub.status.idle": "2021-10-14T18:43:16.492640Z",
          "shell.execute_reply": "2021-10-14T18:43:16.493202Z",
          "shell.execute_reply.started": "2021-10-14T16:43:16.946859Z"
        },
        "papermill": {
          "duration": 0.738675,
          "end_time": "2021-10-14T18:43:16.493379",
          "exception": false,
          "start_time": "2021-10-14T18:43:15.754704",
          "status": "completed"
        },
        "tags": [],
        "id": "c909f1e7",
        "outputId": "c13dadec-9921-4f6e-e8ab-820fbe643694"
      },
      "source": [
        "subm"
      ],
      "id": "c909f1e7",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BraTS21ID</th>\n",
              "      <th>MGMT_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.567605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0.517874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>0.520529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>0.525541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>0.624887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>826</td>\n",
              "      <td>0.510444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>829</td>\n",
              "      <td>0.537831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>833</td>\n",
              "      <td>0.376811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>997</td>\n",
              "      <td>0.560375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1006</td>\n",
              "      <td>0.494730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    BraTS21ID  MGMT_value\n",
              "0           1    0.567605\n",
              "1          13    0.517874\n",
              "2          15    0.520529\n",
              "3          27    0.525541\n",
              "4          37    0.624887\n",
              "..        ...         ...\n",
              "82        826    0.510444\n",
              "83        829    0.537831\n",
              "84        833    0.376811\n",
              "85        997    0.560375\n",
              "86       1006    0.494730\n",
              "\n",
              "[87 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.667885,
          "end_time": "2021-10-14T18:43:18.033836",
          "exception": false,
          "start_time": "2021-10-14T18:43:17.365951",
          "status": "completed"
        },
        "tags": [],
        "id": "cad59fb0"
      },
      "source": [
        ""
      ],
      "id": "cad59fb0",
      "execution_count": null,
      "outputs": []
    }
  ]
}